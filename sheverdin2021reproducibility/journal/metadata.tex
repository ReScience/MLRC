% DO NOT EDIT - automatically generated from metadata.yaml

\def \codeURL{https://github.com/GANA-FACT-AI/gana-fact-ai}
\def \codeDOI{}
\def \codeSWH{swh:1:dir:16f75580c3619b9e0b00b6dceef8e5bf2f5a47c4}
\def \dataURL{}
\def \dataDOI{}
\def \editorNAME{}
\def \editorORCID{}
\def \reviewerINAME{}
\def \reviewerIORCID{}
\def \reviewerIINAME{}
\def \reviewerIIORCID{}
\def \dateRECEIVED{01 November 2018}
\def \dateACCEPTED{}
\def \datePUBLISHED{}
\def \articleTITLE{[Re] Reproducibility report of "Interpretable Complex-Valued Neural Networks for Privacy Protection"}
\def \articleTYPE{Replication}
\def \articleDOMAIN{ML Reproducibility Challenge 2020}
\def \articleBIBLIOGRAPHY{bibliography.bib}
\def \articleYEAR{2021}
\def \reviewURL{https://openreview.net/forum?id=P30M7d9DyXw}
\def \articleABSTRACT{Scope of Reproducibility The original work by  Xiang et al. claimed that complex-valued DNNs effectively increase the difficulty of inferring inputs for the adversary attacks compared to the baseline. In addition, Xiang et al. stated that the proposed privacy-protecting complex-valued DNN effectively preserves the accuracy when compared to the baseline. Methodology Since the original paper's code was not published, all of the codebase was written independently from scratch, based solemnly on how it was described in the paper. We mostly used a Nvidia's 	extit{RTX 2060 Super} as the GPU and a 	extit{AMD Ryzen 3600x} as the CPU.  The runtime of each model was highly dependant on the architecture used. The runtimes for each model can be found in Table 2. Results In contrast to the first claim, we have discovered that for most of the architectures, reconstruction errors for the attacks are quite low, which means that in our models the first claim is not supported. We also found that for most of the models, the classification error is somewhat higher than those provided in the paper. However, these indeed relate to the original work and partially support the second claim of the authors. What was easy Authors of the original paper utilized famous architectures for some of architectures' parts, such as ResNet and LeNet, that were well explained and defined in the literature. In addition, authors, provided formulas on the modified rotation-invariant Complex DNN modules (ReLU, max pooling etc.), implementation of which was relatively straightforward. The paper was based on the openly available datasets. What was difficult The paper did not provide  any information on the architecture of the critic for the WGAN, along with the architecture of the angle discriminator utilized in inversion attack 1. It also does not  provide any information about crucial hyperparameters, such as the k value used for k-anonimity.}
\def \replicationCITE{Liyao Xiang, Haotian Ma, Hao Zhang, Yifan Zhang, Jie Ren, and Quanshi Zhang. 2020. Interpretable complex-valued neural networks for privacy protection.}
\def \replicationBIB{xiang2020interpretable}
\def \replicationURL{http://arxiv.org/abs/1505.04597}
\def \replicationDOI{}
\def \contactNAME{Arsen Sheverdin}
\def \contactEMAIL{arsen.sheverdin@student.uva.nl}
\def \articleKEYWORDS{rescience c, rescience x, machine, learning, deep, complex, valued, neural, network, python, pytorch}
\def \journalNAME{ReScience C}
\def \journalVOLUME{4}
\def \journalISSUE{1}
\def \articleNUMBER{}
\def \articleDOI{}
\def \authorsFULL{Arsen Sheverdin et al.}
\def \authorsABBRV{A. Sheverdin et al.}
\def \authorsSHORT{Sheverdin et al.}
\title{\articleTITLE}
\date{}
\author[1,\orcid{0000-0002-2033-6674}]{Arsen Sheverdin}
\author[1,\orcid{0000-0002-3118-3677}]{Alko Knijff}
\author[1,\orcid{0000-0002-0167-3069}]{Noud Corten}
\author[1,\orcid{0000-0001-5082-9018}]{Georg Lange}
\affil[1]{University of Amsterdam, Amsterdam, The Netherlands}
