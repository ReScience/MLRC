title: "[¬Re] A Reproducibility Case Study of “Fairness Guarantees under Demographic Shift”"

authors:
  - name: Dennis Agafonov
    orcid: 0009-0004-3390-6113
    email: dennis.agafonov@student.uva.nl
    affiliations: 1,\textdagger

  - name: Jelke Matthijsse
    orcid: 0009-0007-3567-9796
    email: jelke.matthijsse@student.uva.nl
    affiliations: 1,\textdagger
 
  - name: Noa Nonkes
    orcid: 0009-0002-4370-1643
    email: noa.nonkes@student.uva.nl
    affiliations: 1,\textdagger

  - name: Zjos van de Sande
    orcid: 0009-0000-6702-8444
    email: zjos.van.de.sande@student.uva.nl
    affiliations: 1,\textdagger,*

affiliations:
  - code:    1
    name:    University of Amsterdam
    address: Amsterdam, The Netherlands

  - code:    "{}\\textdagger"
    name:    Equal contributions

keywords: rescience c, rescience x, machine learning, deep learning, python, pytorch

code:
  - url: https://github.com/noanonkes/fact-guarantee
  - doi: 
  - swh: swh:1:dir:c769bc1fc87a24b6811f318d7ad56ea9a70954e7

data:
  - url:
  - doi:

replication:
 - cite: "S. Giguere, B. Metevier, Y. Brun, P. S. Thomas, S. Niekum, and B. C. da Silva. “Fairness Guarantees under Demographic Shift.” In: International Conference on Learning Representations. 2022."
 - bib: giguere2022fairness
 - url: https://openreview.net/pdf?id=wbPObLm6ueA
 - doi: n/a

abstract: "Scope of Reproducibility — This work studies the reproducibility of the paper Fairness guarantees under demographic shift (2022) by Giguere et al. Specifically, the authors discuss Shifty, an algorithm that provides high‐confidence guarantees that a user‐specified fairness constraint will hold in the case of a demographic shift between training and deployment data. The authors claim that Shifty achieves this without any significant loss of accuracy when compared to a number of other baseline algorithms. \\ Methodology — Using the open‐source code provided by the authors, experiments were conducted to collect the results of Shifty and a number of other baseline algorithms when deployed on three different datasets. Results were collected in the form of accuracy, failure rate, and the probability of not finding a fair solution. The experiments in this reproducibility study were conducted on a total of 115 CPU hours. \\ Results — The claim that Shifty guarantees fairness with high confidence is strongly confirmed by the reproduction results of this study. It was also found in this reproducibility study that Shifty achieves accuracy scores comparable to those of other fairness algorithms. \\ What was easy — The open‐source code was structured in a way that allowed us to make alterations to the experimental setup or the implementations of the models. The original datasets were also provided in a structured manner and were already standardized. \\ What was difficult — Modifications to the code were necessary in order to run this code efficiently and without errors; in the original code, there were packages missing, redundant functions and files, and mistakes in the handling of the user‐specified fairness constraints. \\ Communication with original authors — The authors did not respond to our inquiries, resulting in no communication with the original authors."

bibliography: bibliography.bib

type: Replication

domain: ML Reproducibility Challenge 2022

language: Python

review: 
  - url: https://openreview.net/forum?id=MMuv-v99Hy

contributors:
  - name: Samarth Bhargav
    orcid: 0000-0001-5204-8514
    role: editor
  - name:
    orcid:
    role: reviewer
  - name:
    orcid:
    role: reviewer

dates:
  - received: 04 February 2023
  - accepted:
  - published: 15 June 2023

article:
  - number: 1
  - doi:
  - url:

journal:
  - name: "ReScience C"
  - issn: 2430-3658
  - volume: 9
  - issue: 2
  
