% \begin{table}[]
% \footnotesize
% \centering
% \begin{tabular}{|c|cccccc|}
% \hline
% \multicolumn{7}{|c|}{Accuracy - Unknown Demographic Shift - Demographic Parity} \\ \hline

% Samples & 10k & 20k & 30k & 40k & 50k & 60k \\ \hline

% \multicolumn{7}{|c|}{Seldonian Classifier} \\ \hline
% Original & nan & 61.47 & 72.25 & 66.07 & 72.15 & 74.88 \\ \hline
% Deployed & nan & 64.36 & 73.93 & 66.38 & 70.18 & 72.94 \\ \hline
% Difference & nan & 2.89 & 1.68 & 0.31 & -1.97 & -1.94 \\ \hline

% \multicolumn{7}{|c|}{Quasi-Seldonian-Robust Classifier (Shifty)} \\ \hline
% Original & nan & 59.49 & 64.97 & 76.82 & 65.19 & 68.99  \\ \hline 
% Deployed & nan & 58.72 & 67.40 & 74.92 & 67.61 & 69.32 \\ \hline 
% Difference & nan & -0.77 & 2.43 & -1.90 & 2.42 & 0.33  \\ \hline

% \multicolumn{7}{|c|}{Quasi-Seldonian Classifier} \\ \hline
% Original & nan & 63.55 & 69.08 & 70.57 & 75.22 & 72.54  \\ \hline
% Deployed & nan & 66.34 & 72.65 & 68.96 & 73.67 & 72.89 \\ \hline
% Difference & nan & 2.79 & 3.57 & -1.61 & -1.55 & 0.35  \\ \hline

% \end{tabular}
% \caption{Results table showcasing the numerical mean accuracy percentage of each Seldonian algorithm using the MLP-classifier, for both the original distribution as the deployed one when trained on an unknown demographic shift with fairness constraint Demographic Parity. The decrease or increase in accuracy is shown in the rows named 'difference' }
% \end{table}

% \begin{table}[]
% \footnotesize
% \centering
% \begin{tabular}{|c|cccccc|}
% \hline
% \multicolumn{7}{|c|}{Accuracy - Unknown Demographic Shift - Disparate Impact} \\ \hline

% Samples & 10k & 20k & 30k & 40k & 50k & 60k \\ \hline

% \multicolumn{7}{|c|}{Seldonian Classifier} \\ \hline
% Original & nan & nan & nan & 54.71 & 57.17 & 73.24 \\ \hline
% Deployed & nan & nan & nan & 56.28 & 59.35 & 71.94 \\ \hline
% Difference & nan & nan & nan & 1.57 & 2.18 & -1.30 \\ \hline

% \multicolumn{7}{|c|}{Quasi-Seldonian-Robust Classifier (Shifty)} \\ \hline
% Original & nan & nan & nan & 56.82 & 48.00 & 64.20  \\ \hline 
% Deployed & nan & nan & nan & 59.01 & 49.66 & 67.07 \\ \hline 
% Difference & nan & nan & nan & 2.19 & 1.66 & 2.87   \\ \hline

% \multicolumn{7}{|c|}{Quasi-Seldonian Classifier} \\ \hline
% Original & nan & 61.76 & 45.24 & 62.38 & 57.10 & 64.68   \\ \hline
% Deployed & nan & 61.84 & 46.28 & 67.21 & 60.17 & 64.90  \\ \hline
% Difference & nan & 0.08 & 1.04 & 4.83 & 3.07 & 0.22  \\ \hline

% \end{tabular}
% \caption{Results table showcasing the numerical mean accuracy percentage of each Seldonian algorithm using the MLP-classifier, for both the original distribution as the deployed one when trained on an unknown demographic shift with fairness constraint Disparate Impact. The decrease or increase in accuracy is shown in the rows named 'difference' }
% \end{table}

\begin{table}[ht]
\footnotesize 
\centering
\begin{tabular}{|c|ccccccccccc|} \hline \multicolumn{12}{|c|}{Accuracy - Known Demographic Shift - Demographic Parity} \\ \hline \hline

Samples & 10k & 15k & 20k & 25k & 30k & 35k & 40k & 45k & 50k & 55k & 60k \\ \hline

\multicolumn{12}{|c|}{Seldonian Classifier} \\ \hline
Original & nan & nan & nan & nan & nan & nan & nan & nan & 63.40 & 62.07 & nan \\ \hline
Deployed & nan & nan & nan & nan & nan & nan & nan & nan & 63.72 & 63.29 & nan  \\ \hline 
Difference & nan & nan & nan & nan & nan & nan & nan & nan & 0.32 & 1.22 & nan  \\ \hline

\multicolumn{12}{|c|}{Quasi-Seldonian-Robust Classifier (\textbf{\texttt{Shifty}})} \\ \hline
Original & nan & nan & nan & nan & 53.99 & nan & nan & 72.87 & 50.04 & 73.24 & 54.11  \\ \hline
Deployed & nan & nan & nan & nan & 54.86 & nan & nan & 70.25 & 47.76 & 70.77 & 53.04  \\ \hline
Difference & nan & nan & nan & nan & 0.87 & nan & nan & -2.62 & -2.28 & -2.47 & -1.07  \\ \hline

\multicolumn{12}{|c|}{Quasi-Seldonian Classifier} \\ \hline
Original & nan & nan & 40.99 & 62.80 & nan & 55.11 & nan & 62.98 & 68.80 & 71.24 & 65.09 \\ \hline
Deployed & nan & nan & 40.66 & 60.54 & nan & 55.71 & nan & 59.87 & 68.60 & 70.81 & 65.67  \\ \hline
Difference & nan & nan & -0.33 & -2.26 & nan & 0.60 & nan & -3.11 & -0.20 & -0.43 & 0.58 \\ \hline
\end{tabular}
\caption{Results table showcasing the numerical mean accuracy (in percentages) of each Seldonian algorithm using the MLP-classifier and the \textit{UCI Adult Census} dataset, for both the original and deployment distribution when trained on a known demographic shift with the fairness constraint DP. The decrease or increase in accuracy is shown in the rows named `difference'.}
\label{tab:add_results}
\end{table}


% \begin{table}[] 
% \footnotesize 
% \begin{tabular}{|c|ccccccccccc|} \hline \multicolumn{12}{|c|}{Accuracy - Known Demographic Shift - Disparate Impact} \\ \hline \hline

% Samples & 10k & 15k & 20k & 25k & 30k & 35k & 40k & 45k & 50k & 55k & 60k \\ \hline

% \multicolumn{12}{|c|}{Seldonian Classifier} \\ \hline
% Original & nan & nan & nan & 62.25 & 59.89 & 71.01 & 71.16 & nan & 72.32 & nan & 70.70  \\ \hline
% Deployed & nan & nan & nan & 60.67 & 58.71 & 70.04 & 69.46 & nan & 70.97 & nan & 69.51  \\ \hline 
% Difference & nan & nan & nan & -1.58 & -1.18 & -0.97 & -1.70 & nan & -1.35 & nan & -1.19   \\ \hline

% \multicolumn{12}{|c|}{Quasi-Seldonian-Robust Classifier (Shifty)} \\ \hline
% Original & nan & nan & 55.76 & 61.60 & 60.51 & 69.66 & 69.59 & nan & 58.39 & nan & nan   \\ \hline
% Deployed & nan & nan & 54.81 & 61.01 & 59.35 & 68.30 & 68.25 & nan & 58.50 & nan & nan   \\ \hline
% Difference & nan & nan & -0.95 & -0.59 & -1.16 & -1.36 & -1.34 & nan & 0.11 & nan & nan   \\ \hline

% \multicolumn{12}{|c|}{Quasi-Seldonian Classifier} \\ \hline
% Original & nan & nan & nan & 57.97 & 72.67 & 65.79 & 73.86 & 70.06 & 75.08 & nan & nan  \\ \hline
% Deployed & nan & nan & nan & 57.35 & 71.16 & 64.78 & 72.28 & 68.82 & 72.77 & nan & nan   \\ \hline
% Difference & nan & nan & nan & -0.62 & -1.51 & -1.01 & -1.58 & -1.24 & -2.31 & nan & nan \\ \hline
% \end{tabular}
% \caption{Results table showcasing the numerical mean accuracy percentage of each Seldonian algorithm using the MLP-classifier, for both the original distribution as the deployed one when trained on a known demographic shift with fairness constraint Disparate Impact. The decrease or increase in accuracy is shown in the rows named 'difference' }
% \end{table}