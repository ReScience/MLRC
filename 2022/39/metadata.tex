\def \codeURL{https://github.com/Dawlau/FACT-AI}
\def \codeDOI{10.5281/zenodo.7932857}
\def \dataURL{}
\def \dataDOI{}
\def \editorNAME{}
\def \editorORCID{}
\def \reviewerINAME{}
\def \reviewerIORCID{}
\def \reviewerIINAME{}
\def \reviewerIIORCID{}
\def \dateRECEIVED{03 February 2023}
\def \dateACCEPTED{}
\def \datePUBLISHED{}
\def \articleTITLE{Reproducibility Study of “CrossWalk: Fairness-enhanced Node Representation Learning”}
\def \articleTYPE{Replication}
\def \articleDOMAIN{ML Reproducibility Challenge 2022}
\def \articleBIBLIOGRAPHY{bibliography.bib}
\def \articleYEAR{2023}
\def \reviewURL{https://openreview.net/forum?id=tpk45Zll8eh}
\def \articleABSTRACT{Scope of Reproducibility
  This work aims to reproduce the findings of the paper \"CrossWalk: Fairness-enhanced Node Representation Learning\" by investigating the two main claims made by the authors about CrossWalk, which suggest that (i) CrossWalk enhances fairness in three graph algorithms, while only suffering from small decreases in performance, and that (ii) CrossWalk preserves the necessary structural properties of the graph while reducing disparity.

  Methodology
  The authors made the CrossWalk repository available, which contained most of the datasets used for their experimentation, and the scripts needed to run the experiments. However, the codebase lacked documentation and was missing logic for running all experiments and visualizing the results. We, therefore, re-implement their code from scratch and deploy it as a python package which can be run to obtain all the showcased results. 

  Results
  Our work suggests that the first claim of the paper, which states that Crosswalk minimizes disparity and thus enhances fairness is partially reproducible, and only for the tasks of Node classification and Influence maximization as the parameters specified in the paper do not always yield similar results. Then, the second claim of the paper which states that Crosswalk attains the necessary structural properties of the graph is fully reproducible through our experiments.

  What was easy
  The original paper contained the necessary information about hyperparameters, which coupled with the publicly available repository made it straightforward to refactor the code and understand the idea of the proposed method. 

  What was difficult
  The difficulty stems from the lack of structure and documentation in the provided code which made the original experiments hard to reproduce. Furthermore, there were missing files in the provided datasets. Also, some experiments were not reproducible at all through the provided code. One more important aspect is that the experiments are CPU intensive which made the reproducibility even harder.

  Communication with original authors
  Albeit rather late, the authors provided meaningful feedback on our questions about implementation details and initial results.}
\def \replicationCITE{A. Khajehnejad, M. Khajehnejad, M. Babaei, K. P. Gummadi, A. Weller, and B. Mirzasoleiman. CrossWalk: Fairness-enhanced Node Representation Learning. 2021}
\def \replicationBIB{crosswalk}
\def \replicationURL{https://arxiv.org/pdf/2105.02725.pdf}
\def \replicationDOI{10.48550/arXiv.2105.02725}
\def \contactNAME{Luca Pantea}
\def \contactEMAIL{luca.pantea@student.uva.nl}
\def \articleKEYWORDS{rescience c, rescience x, machine learning, Fairness in Machine Learning, Representational Learning, Graph Algorithms}
\def \journalNAME{ReScience C}
\def \journalVOLUME{9}
\def \journalISSUE{2}
\def \articleNUMBER{1}
\def \articleDOI{}
\def \authorsFULL{Luca Pantea, Andrei Blahovici}
\def \authorsABBRV{L. Pantea and A. Blahovici}
\def \authorsSHORT{Pantea and Blahovici}
\title{\articleTITLE}
\date{}
\author[1,\orcid{0009-0007-2511-1953}]{Luca Pantea}
\author[2,\orcid{0009-0004-8216-0397}]{Andrei Eusebiu Blahovici}
\affil[1,2]{University of Amsterdam}