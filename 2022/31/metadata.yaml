# To be filled by the author(s) at the time of submission
# -------------------------------------------------------

# Title of the article:
#  - For a successful replication, it should be prefixed with "[Re]"
#  - For a failed replication, it should be prefixed with "[¬Re]"
#  - For other article types, no instruction (but please, not too long)
# Change the default title
title: "[Re] Variational Neural Cellular Automata"

# List of authors with name, orcid number, email and affiliation
# Affiliation "*" means contact author (required even for single-authored papers)
authors:
  - name: Albert Aillet
    orcid: 0009-0006-1437-2667
    email: albesa@kth.se
    affiliations: 1,*

  - name: Simon Sondén
    orcid: 0009-0002-6393-6490
    email: ssonden@kth.se
    affiliations: 1 # * is for contact author

# List of affiliations with code (corresponding to author affiliations), name
# and address. You can also use these affiliations to add text such as "Equal
# contributions" as name (with no address).
affiliations:
  - code: 1
    name: Equal contributions
    address: KTH Royal Institute of Technology

# List of keywords (adding the programming language might be a good idea)
keywords: rescience c, machine learning, deep learning, python, jax,

# Code URL and DOI/SWH (url is mandatory for replication, doi after acceptance)
# You can get a DOI for your code from Zenodo, or an SWH identifier from
# Software Heritage.
#   see https://guides.github.com/activities/citable-code/
code:
  - url: https://github.com/albertaillet/vnca
  - doi: 10.5281/zenodo.7927205
  - swh: "swh:1:dir:3de126d09281c3dab4749dc8ac9330e53a22c558"

# Data URL and DOI (optional if no data)
data:
  - url:
  - doi:

# Information about the original article that has been replicated
replication:
  - cite: Rasmus Berg Palm, Miguel González-Duque, Shyam Sudhakaran, Sebastian Risi "Variational Neural Cellular Automata" International Conference on Learning Representations. ICLR, 2022.
  - bib: palm2022variational
  - url: https://openreview.net/forum?id=7fFO4cMBx_9
  - doi: # Regular digital object identifier

# Don't forget to surround abstract with double quotes
abstract: "The main claim of the paper being reproduced is that the proposed Variational Neural Cellular Automata (VNCA) architecture, composed of a convolutional encoder and a Neural Cellular Automata (NCA)-based decoder, is able to generate high-quality samples. The paper presents two variants of this VNCA decoder: the doubling VNCA variant that is claimed to have a simple latent space, and the non-doubling VNCA variant that is claimed to be optimized for damage recovery and stability over many steps. To reproduce the results, we re-implemented all of the VNCA models and a fully-convolutional baseline in JAX, by using the descriptions given in the paper. We then followed the same experimental setup and hyperparameter choices as in the original paper.  All of the models were trained on a TPU v3-8 provided by Kaggle, with a total budget of around 4 TPU hours, not counting unreported experiments. All but one of the figures and results from the original study were possible to reproduce. The obtained Evidence Lower Bound (ELBO) of the doubling VNCA was within 0.3\\% of the stated and for the non-doubling VNCA the ELBO was within 1.8\\%  and the observed damage recovery was similar. We were however not able to reproduce the t-SNE reduction experiment for the baseline and were therefore not able to show the VNCA decoder having a cleaner t-SNE separation than the baseline. The implementation of the convolutional baseline and most parts of the NCA-based decoder were straightforward to re-implement based on the description provided in the paper. One of the difficulties faced in the reproduction study was obtaining the labels of the binarized MNIST dataset used in the original paper since it officially is provided without labels. This made it unclear how the original paper got the labels for the latent space visualization. Additionally, implementing the pool for the non-doubling version of the VNCA model with a distributed training setup was challenging as it required operations between TPU cores."

# Bibliography file (yours)
bibliography: bibliography.bib

# Type of the article
# Type can be:
#  * Editorial
#  * Letter
#  * Replication
type: Replication

# Scientific domain of the article (e.g. Computational Neuroscience)
#  (one domain only & try to be not overly specific)
domain: ML Reproducibility Challenge 2022

# Coding language (main one only if several)
language: Python

# To be filled by the author(s) after acceptance
# -----------------------------------------------------------------------------

# For example, the URL of the GitHub issue where review actually occured
review:
  - url: https://openreview.net/forum?id=d7-ns6SZqp

contributors:
  - name: Koustuv Sinha,\\ Maurits Bleeker,\\ Samarth Bhargav
    orcid:
    role: editor
  - name:
    orcid:
    role: reviewer
  - name:
    orcid:
    role: reviewer

# This information will be provided by the editor
dates:
  - received:  February 4, 2023
  - accepted:  April 19, 2023
  - published:  July 20, 2023

# This information will be provided by the editor
article:
  - number: 31
  - doi: 10.5281/zenodo.6574623
  - url: https://zenodo.org/record/6574623/files/article.pdf

# This information will be provided by the editor
journal:
  - name: "ReScience C"
  - issn: 2430-3658
  - volume: 9
  - issue: 2
