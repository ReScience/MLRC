# To be filled by the author(s) at the time of submission
# -------------------------------------------------------

# Title of the article:
#  - For a successful replication, it shoudl be prefixed with "[Re]"
#  - For a failed replication, it should be prefixed with "[¬Re]"
#  - For other article types, no instruction (but please, not too long)
title: "[Re] Fairness Guarantees under Demographic Shift"

# List of authors with name, orcid number, email and affiliation
# Affiliation "*" means contact author
authors:
  - name: Valentin Leonhard Buchner
    orcid: 0000-0002-1262-3016
    email: valentin.buchner@student.uva.nl
    affiliations: 1,2,*      # * is for contact author

  - name: Philip Onno Olivier Schutte
    orcid: 0009-0005-6198-2743
    email: philip.schutte@student.uva.nl
    affiliations: 1

  - name: Yassin Ben Allal
    orcid: 0009-0006-9583-1705
    email: y.ben.allal@student.vu.nl
    affiliations: 1,2

  - name: Hamed Ahadi
    orcid: 0000-0002-3277-3644
    email: hamed.ahadi@student.uva.nl
    affiliations: 1,2
  

# List of affiliations with code (corresponding to author affiliations), name
# and address. You can also use these affiliations to add text such as "Equal
# contributions" as name (with no address).
affiliations:
  - code:    1
    name:    University of Amsterdam
    address: Amsterdam, the Netherlands
    
  - code:    2
    name:    Vrije Universiteit Amsterdam
    address: Amsterdam, The Netherlands


# List of keywords (adding the programming language might be a good idea)
keywords: Fairness and Bias in ML, Fair Machine Learning, Reproduction, rescience c, machine learning

# Code URL and DOI (url is mandatory for replication, doi after acceptance)
# You can get a DOI for your code from Zenodo,
#   see https://guides.github.com/activities/citable-code/
code:
  - url: https://github.com/YasBenAll/fact-ai-project
  - doi: 10.5281/zenodo.7916507
  - swh: swh:1:dir:436c48ce9cf36b10ee3cdcd537a06c9df2cd53cc

# Data URL and DOI (optional if no data)
data:
  - url:
  - doi:

# Information about the original article that has been replicated
replication:
 - cite: "S. Giguere, B. Metevier, B. Castro da Silva, Y. Brun, P. Thomas, and S. Niekum. “Fairness guarantees under demographic shift.” In: International Conference on Learning Representations. 2022."
 - bib:  giguere2022 # Bibtex key (if any) in your bibliography file
 - url:  https://openreview.net/pdf?id=wbPObLm6ueA # URL to the PDF, try to link to a non-paywall version
 - doi:  # Regular digital object identifier

# Don't forget to surround abstract with double quotes
abstract: "Scope of Reproducibility — The original authors’ main contribution is the family of Shifty algorithms, which can guarantee that certain fairness constraints will hold with high confidence even after a demographic shift in the deployment population occurs. They claim that Shifty provides these high‐confidence fairness guarantees without a loss in model performance, given enough training data. Methodology — The code provided by the original paper was used, and only some small adjustments needed to be made in order to reproduce the experiments. All model specifications and hyperparameters from the original implementation were used. Extending beyond reproducing the original paper, we investigated the sensibility of Shifty to the size of the bounding intervals limiting the possible demographic shift, and ran shifty with an additional optimization method. Results — Our results approached the results reported in the original paper. They supported the claim that Shifty reliably guarantees fairness under demographic shift, but could not verify that Shifty performs at no loss of accuracy. What was easy — The theoretical framework laid out in the original paper was well explained and supported by additional formulas and proofs in the appendix. Further, the authors provided clear instructions on how to run the experiments and provided necessary hyperparameters. What was difficult — While an open‐source implementation of Shifty was provided and was debugged with relatively low time investment, the code did not contain extensive documentation and was complex to understand. It was therefore difficult to verify that each part of the code functions as expected and to expand upon the existing experiments. Further, certain hyperparameter and model specifications deviated between the provided code and the original paper, which made it challenging to know which specifications to apply when reproducing. Communication with original authors — The first author of the original paper was contacted, but unfortunately we have yet to receive a reply."

# Bibliography file (yours)
bibliography: bibliography.bib
  
# Type of the article
# Type can be:
#  * Editorial
#  * Letter
#  * Replication
type: Replication

# Scientific domain of the article (e.g. Computational Neuroscience)
#  (one domain only & try to be not overly specific)
domain: ML Reproducibility Challenge 2022

# Coding language (main one only if several)
language: Python

  
# To be filled by the author(s) after acceptance
# -----------------------------------------------------------------------------

# For example, the URL of the GitHub issue where review actually occured
review: 
  - url: https://openreview.net/forum?id=xEfg6h1GFmW&noteId=C0AfhPXAYB

contributors:
  - name: Samarth Bhargav
    orcid: 0000-0001-5204-8514
    role: editor
  - name: Anonymous Reviewers
    orcid:
    role: reviewer
  - name:
    orcid:
    role: reviewer

# This information will be provided by the editor
dates:
  - received: 04 February 2023
  - accepted: 
  - published: 15 June 2023

# This information will be provided by the editor
article:
  - number: 13 # Article number will be automatically assigned during publication
  - doi:    # DOI from Zenodo
  - url:    # Final PDF URL (Zenodo or rescience website?)

# This information will be provided by the editor
journal:
  - name: "ReScience C"
  - issn: 2430-3658
  - volume: 9
  - issue: 2
