% DO NOT EDIT - automatically generated from metadata.yaml

\def \codeURL{https://github.com/martentyrk/mlrc2022hirota}
\def \codeDOI{}
\def \codeSWH{swh:1:dir:2b9535456facf442ee411ab4cae5d3c4ce1cc29e}
\def \dataURL{}
\def \dataDOI{}
\def \editorNAME{Koustuv Sinha,\\ Maurits Bleeker,\\ Samarth Bhargav}
\def \editorORCID{}
\def \reviewerINAME{}
\def \reviewerIORCID{}
\def \reviewerIINAME{}
\def \reviewerIIORCID{}
\def \dateRECEIVED{04 February 2023}
\def \dateACCEPTED{19 April 2023}
\def \datePUBLISHED{20 July 2023}
\def \articleTITLE{[Re] Exploring the Explainability of Bias in Image Captioning Models}
\def \articleTYPE{Replication}
\def \articleDOMAIN{ML Reproducibility Challenge 2022}
\def \articleBIBLIOGRAPHY{bibliography.bib}
\def \articleYEAR{2023}
\def \reviewURL{https://openreview.net/forum?id=N9Wn91tE7D0}
\def \articleABSTRACT{Scope of Reproducibility: The main objective of this paper is to reproduce and verify the following claims made in the original paper: (1) According to the LIC metric, all evaluated image captioning models amplify gender and racial bias, (2) the proposed LIC metric is robust against encoders, and (3) captioning model NIC+Equalizer amplifies gender bias beyond baseline. Methodology: We reproduced the results of the original authors with only minor modifications to the code they made available. We contribute to their research by highlighting a noteworthy limitation in the used data split and propose an integrated gradients method to increase explainability, allowing users to understand predictions better using the Captum library for Pytorch. As for the computational requirements, all experiments were run on a cluster with a NVIDIA Titan RTX GPU and the time required to run a total of 720 models was ∼98 hours. Results:  The results we obtained showed the same patterns as in the original authors work. All our results were in the range of ±1 LIC score units compared to the original work, which supports the claims on the gender and racial bias amplification, robustness against encoders, and amplification by NIC+Equalizer beyond baseline. As for our contributions, we show that the attribution scores obtained by using integrated gradients follow similar patterns in terms of gender amplification for all evaluated language models, providing additional support for the proposed LIC metric. During data set analysis we observed a leakage in the original data split being used, resulting in identical captions occurring multiple times in both the training and test set. The removal of already seen captions during training from the test set reduced its size by 62.4\% on average and caused a decline in LIC_M scores of approximately 5 units. What was easy: Reproducing the results using the original provided code offered no difficulties. What was difficult: Finding a useful angle of contribution to the paper proved to be challenging. After we had decided upon using our selected explainability method, implementing and modifying existing code was more work than expected.}
\def \replicationCITE{Hirota, Yusuke and Nakashima, Yuta and Garcia, Noa. “Quantifying Societal Bias Amplification in Image Captioning”, CVPR, 2022.}
\def \replicationBIB{hirotapaper}
\def \replicationURL{https://arxiv.org/abs/2203.15395}
\def \replicationDOI{10.48550/arXiv.2203.15395}
\def \contactNAME{Luyang Busser}
\def \contactEMAIL{luyang.busser@student.uva.nl}
\def \articleKEYWORDS{rescience c, machine learning, deep learning, python, pytorch, reproducibility, fairness, gender, race, LIC, LIC score, integrated gradients, MSCOCO, Captum, bias amplification, encoders, captioning models, LSTM, BERT}
\def \journalNAME{ReScience C}
\def \journalVOLUME{9}
\def \journalISSUE{2}
\def \articleNUMBER{21}
\def \articleDOI{}
\def \authorsFULL{Marten Türk et al.}
\def \authorsABBRV{M. Türk et al.}
\def \authorsSHORT{Türk et al.}
\title{\articleTITLE}
\date{}
\author[1,\orcid{0009-0002-9142-2753}]{Marten Türk}
\author[1,\orcid{0009-0004-4565-390X}]{Luyang Busser}
\author[1,\orcid{0009-0004-2571-842X}]{Daniël van Dijk}
\author[1,\orcid{0009-0005-6736-1390}]{Max J.A. Bosch}
\affil[1]{University of Amsterdam, Amsterdam, The Netherlands}
\affil[1]{Equal contribution}
