% DO NOT EDIT - automatically generated from metadata.yaml

\def \codeURL{https://github.com/JonaRuthardt/MLRC-CartoonX}
\def \codeDOI{}
\def \codeSWH{swh:1:dir:691b7400b38017cfe651a59735dc715755388c4d;origin=https://github.com/JonaRuthardt/MLRC-CartoonX;visit=swh:1:snp:ffead088e1c166ac58b0f37c5c8e87344f638b3d;anchor=swh:1:rev:38364e7eef0fbc99f2b143fad90a29dae113f95c}
\def \dataURL{}
\def \dataDOI{}
\def \editorNAME{Koustuv Sinha,\\ Maurits Bleeker,\\ Samarth Bhargav}
\def \editorORCID{}
\def \reviewerINAME{}
\def \reviewerIORCID{}
\def \reviewerIINAME{}
\def \reviewerIIORCID{}
\def \dateRECEIVED{04 February 2023}
\def \dateACCEPTED{19 April 2023}
\def \datePUBLISHED{20 July 2023}
\def \articleTITLE{[Re] On the Reproducibility of CartoonX}
\def \articleTYPE{Replication}
\def \articleDOMAIN{ML Reproducibility Challenge 2022}
\def \articleBIBLIOGRAPHY{bibliography.bib}
\def \articleYEAR{2023}
\def \reviewURL{https://openreview.net/forum?id=MK4IQJdLLeo}
\def \articleABSTRACT{Scope of Reproducibility — CartoonX [1] is a novel explanation method for image classifiers. In this reproducibility study, we examine the claims of the original authors of CartoonX that it: (i) extracts relevant piece‐wise smooth parts of the image, resulting in explanations which are more straightforward to interpret for humans; (ii) achieves lower distortion in the model output, using fewer coefficients than other state-of‐the‐art methods; (iii) is model‐agnostic. Finally, we examine how to reduce the runtime.
Methodology — The original authors’ open‐sourced implementation has been used to examine (i). We implemented the code to examine (ii), as there was no public code available for this. We tested claim (iii) by performing the same experiments with a Vision Transformer instead of a CNN. To reduce the runtime, we extended the existing implementation with multiple enhanced initialization techniques. All experiments took approximately 38.4 hours on a single NVIDIA Titan RTX.
Results — Our results support the claims made by the original authors. (i) We observe that CartoonX produces piece‐wise smooth explanations. Most of the explanations give valuable insights. (ii) Most experiments, that show how CartoonX achieves lower distortion outputs compared to other methods, have been reproduced. In the cases where exact reproducibility has not been achieved, claim (ii) of the author still holds. (iii) The model‐agnosticism claim still holds as the overall quality of the ViT‐based explanations almost matches that of the CNN‐based explanations. Finally, simple heuristical initializations did not improve the runtime.
What was easy — The mathematical background and intuition of CartoonX were clearly explained by the original authors. Moreover, the original author’s code was well structured and documented, which made it straightforward to run and extend.
What was difficult — Some hyperparameter settings and implementation details needed to reproduce the experiments were not clear or transparent from the original paper or code. This made it difficult to implement and reproduce these experiments.
Communication with original authors — We have been in brief communication with the original authors. They were able to address most of our points, providing us with some additional clarifications about the exact implementation and hyperparameter settings.}
\def \replicationCITE{Kolek, S., and Nguyen, D.A., and Levie, R., and Bruna, J., and Kutyniok, G. "Cartoon Explanations of Image Classifiers."  European Conference on Computer Vision (ECCV) 2022, 2022.}
\def \replicationBIB{cartoonX}
\def \replicationURL{https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136720439.pdf}
\def \replicationDOI{https://doi.org/10.1007/978-3-031-19775-8_26}
\def \contactNAME{Elias Dubbeldam}
\def \contactEMAIL{elias.dubbeldam@student.uva.nl}
\def \articleKEYWORDS{machine learning, artificial intelligence, deep learning, reproducibility, explainable AI, explanation methods, image classifiers, CartoonX, piece-wise smooth, Vision Transformer, runtime efficiency, Python, rescience c}
\def \journalNAME{ReScience C}
\def \journalVOLUME{9}
\def \journalISSUE{2}
\def \articleNUMBER{10}
\def \articleDOI{10.5281/zenodo.8173672}
\def \authorsFULL{Elias Dubbeldam et al.}
\def \authorsABBRV{E. Dubbeldam et al.}
\def \authorsSHORT{Dubbeldam et al.}
\title{\articleTITLE}
\date{}
\author[1,\orcid{0009-0001-0665-4545}]{Elias Dubbeldam}
\author[1,\orcid{0009-0009-7785-8885}]{Aniek Eijpe}
\author[1,\orcid{0000-0002-3077-8302}]{Jona Ruthardt}
\author[1,\orcid{0009-0005-8409-0641}]{Robin Sasse}
\affil[1]{University of Amsterdam, Amsterdam, The Netherlands}
\affil[1]{Equal contribution}
