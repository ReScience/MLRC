# To be filled by the author(s) at the time of submission
# -------------------------------------------------------

# Title of the article:
#  - For a successful replication, it should be prefixed with "[Re]"
#  - For a failed replication, it should be prefixed with "[¬Re]"
#  - For other article types, no instruction (but please, not too long)
title: "[Re] Reproducibility study - Does enforcing diversity in hidden states of LSTM-Attention models improve transparency?"

# List of authors with name, orcid number, email and affiliation
# Affiliation "*" means contact author (required even for single-authored papers)
authors:
  - name: Pieter Bouwman
    orcid: 0000-0002-1697-792X
    email: pieter.bouwman@student.uva.nl
    affiliations: 1,*      # * is for contact author
  - name: Yun Li
    orcid: 0000-0002-2715-3168
    email: liyun.elf@gmail.com
    affiliations: 1
  - name: Rogier van der Weerd
    orcid: 0000-0002-7791-2580
    email: rogier.van.der.weerd@student.uva.nl
    affiliations: 1
  - name: Frank Verhoef
    orcid: 0000-0001-6235-7177
    email: fsa.verhoef@chello.nl
    affiliations: 1

# List of affiliations with code (corresponding to author affiliations), name
# and address. You can also use these affiliations to add text such as "Equal
# contributions" as name (with no address).
affiliations:
  - code:    1
    name:    University of Amsterdam
    address: Amsterdam, The Netherlands


# List of keywords (adding the programming language might be a good idea)
keywords: Attention, NLP, Transparency, Explainability, Faithfulness, Plausibility, Reproducibility, LSTM, ReScience

# Code URL and DOI/SWH (url is mandatory for replication, doi after acceptance)
# You can get a DOI for your code from Zenodo, or an SWH identifier from
# Software Heritage.
#   see https://guides.github.com/activities/citable-code/
code:
  - url: https://anonymous.4open.science/r/FACT_AI_project/
  - doi: 
  - swh: 

# Data URL and DOI (optional if no data)
data:
  - url:
  - doi:

# Information about the original article that has been replicated
replication:
 - cite: "A. K. Mohankumar, P. Nema, S. Narasimhan, M. M. Khapra, B. V. Srinivasan, and B. Ravindran. Towards Transparent and Explainable Attention Models. In: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. Online: Association for Computational Linguistics, July 2020, pp. 4206–4216. DOI: 10.18653/v1/2020.acl-main.387. URL: https://www.aclweb.org/anthology/2020.acl-main.387." # Full textual citation
 - bib:  mohankumar_towards_2020 # Bibtex key (if any) in your bibliography file
 - url:  https://www.aclweb.org/anthology/2020.acl-main.387 # URL to the PDF, try to link to a non-paywall version
 - doi:  10.18653/v1/2020.acl-main.387 # Regular digital object identifier

# Don't forget to surround abstract with double quotes
abstract: "It has been shown that the weights in attention mechanisms do not necessarily offer a faithful explanation of the model's predictions. 
           In the paper Towards Transparent and Explainable Attention Models the authors propose two methods 
           to enhance faithfulness and plausibility of the explanations provided by an LSTM model combined with a basic attention mechanism. 
           For this reproducibility study, we focus on the main claims made in this paper:
           (i) The attention weights in standard LSTM attention models do not provide faithful and plausible explanations for its predictions,
           potentially because the conicity of the LSTM hidden vectors is high. 
           (ii) Two methods can be applied to reduce conicity: Orthogonalization and Diversity Driven Training. 
           The authors claim that applying these methods results in attention weights that offer more faithful and plausible explanations of the model's predictions, without sacrificing model performance.
           We follow four investigative routes: Replication, Code review, Evaluation methodology, Generalization to other architectures.
           We confirm that the Orthogonal and Diversity LSTM achieve similar accuracies as the Vanilla LSTM, while lowering conicity. 
           However, we cannot reproduce the results of several of the experiments in the paper that underlie their claim of better transparency. 
           In addition, a close inspection of the code base reveals some potentially problematic inconsistencies. 
           Despite this, under certain conditions, we do confirm that the Orthogonal and Diversity LSTM can be useful methods to increase transparency. 
           How to formulate these conditions more generally remains unclear and deserves further research. 
           Tasks with a single input sequence appear to benefit most from the methods. 
           For these tasks, the attention mechanism does not play a critical role for achieving performance."

# Bibliography file (yours)
bibliography: bibliography.bib
  
# Type of the article
# Type can be:
#  * Editorial
#  * Letter
#  * Replication
type: Replication

# Scientific domain of the article (e.g. Computational Neuroscience)
#  (one domain only & try to be not overly specific)
domain: ML Reproducibility Challenge 2020, Natural Language Processing

# Coding language (main one only if several)
language: Python

  
# To be filled by the author(s) after acceptance
# -----------------------------------------------------------------------------

# For example, the URL of the GitHub issue where review actually occured
review: 
  - url: https://openreview.net/forum?id=lE0wqKGROKa

contributors:
  - name:
    orcid: 
    role: editor
  - name:
    orcid:
    role: reviewer
  - name:
    orcid:
    role: reviewer

# This information will be provided by the editor
dates:
  - received:  
  - accepted:
  - published: 

# This information will be provided by the editor
article:
  - number: # Article number will be automatically assigned during publication
  - doi:    # DOI from Zenodo
  - url:    # Final PDF URL (Zenodo or rescience website?)

# This information will be provided by the editor
journal:
  - name:  
  - issn:  
  - volume: 
  - issue:  
