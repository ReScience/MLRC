\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\abx@aux@refcontext{none/global//global/global}
\abx@aux@cite{zoubin2020}
\abx@aux@segm{0}{0}{zoubin2020}
\abx@aux@cite{zoubin2020}
\abx@aux@segm{0}{0}{zoubin2020}
\abx@aux@cite{kuznetsova2018open}
\abx@aux@segm{0}{0}{kuznetsova2018open}
\abx@aux@cite{tajbakhsh2016convolutional}
\abx@aux@segm{0}{0}{tajbakhsh2016convolutional}
\abx@aux@cite{tajbakhsh2016convolutional}
\abx@aux@segm{0}{0}{tajbakhsh2016convolutional}
\abx@aux@cite{pmlr-v124-kugelgen20a}
\abx@aux@segm{0}{0}{pmlr-v124-kugelgen20a}
\abx@aux@cite{sohn2020fixmatch}
\abx@aux@segm{0}{0}{sohn2020fixmatch}
\abx@aux@cite{berthelot2019mixmatch}
\abx@aux@segm{0}{0}{berthelot2019mixmatch}
\abx@aux@cite{kurakin2020remixmatch}
\abx@aux@segm{0}{0}{kurakin2020remixmatch}
\abx@aux@cite{li2020dividemix}
\abx@aux@segm{0}{0}{li2020dividemix}
\abx@aux@cite{sohn2020fixmatch}
\abx@aux@segm{0}{0}{sohn2020fixmatch}
\HyPL@Entry{0<</S/D>>}
\babel@aux{american}{}
\pgfsyspdfmark {pgfid1}{8391059}{49131591}
\newmarginnote{note.1.1}{{1}{8391059sp}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\abx@aux@cite{ben2008does}
\abx@aux@segm{0}{0}{ben2008does}
\abx@aux@cite{ben2008does}
\abx@aux@segm{0}{0}{ben2008does}
\abx@aux@cite{chapelle2010semi}
\abx@aux@segm{0}{0}{chapelle2010semi}
\abx@aux@cite{scholkopf2012causal}
\abx@aux@segm{0}{0}{scholkopf2012causal}
\abx@aux@cite{scholkopf2012causal}
\abx@aux@segm{0}{0}{scholkopf2012causal}
\abx@aux@cite{pmlr-v124-kugelgen20a}
\abx@aux@segm{0}{0}{pmlr-v124-kugelgen20a}
\abx@aux@cite{tarvainenweight}
\abx@aux@segm{0}{0}{tarvainenweight}
\abx@aux@cite{zhang2018generalized}
\abx@aux@segm{0}{0}{zhang2018generalized}
\abx@aux@cite{ghosh2015making}
\abx@aux@segm{0}{0}{ghosh2015making}
\abx@aux@cite{ghosh2015making}
\abx@aux@segm{0}{0}{ghosh2015making}
\abx@aux@cite{zhang2018generalized}
\abx@aux@segm{0}{0}{zhang2018generalized}
\abx@aux@cite{zhang2018generalized}
\abx@aux@segm{0}{0}{zhang2018generalized}
\abx@aux@cite{zhang2018generalized}
\abx@aux@segm{0}{0}{zhang2018generalized}
\abx@aux@cite{zhang2018generalized}
\abx@aux@segm{0}{0}{zhang2018generalized}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Related work}{2}{section.2}\protected@file@percent }
\newlabel{sec:related_work}{{2}{2}{Related work}{section.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Noisy labeling and noise-robust loss.}{2}{paragraph*.1}\protected@file@percent }
\abx@aux@cite{zhang2018generalized}
\abx@aux@segm{0}{0}{zhang2018generalized}
\abx@aux@cite{patrini2017making}
\abx@aux@segm{0}{0}{patrini2017making}
\abx@aux@cite{li2020dividemix}
\abx@aux@segm{0}{0}{li2020dividemix}
\abx@aux@cite{li2020dividemix}
\abx@aux@segm{0}{0}{li2020dividemix}
\abx@aux@cite{arazo2019unsupervised}
\abx@aux@segm{0}{0}{arazo2019unsupervised}
\abx@aux@cite{li2020dividemix}
\abx@aux@segm{0}{0}{li2020dividemix}
\abx@aux@cite{li2020dividemix}
\abx@aux@segm{0}{0}{li2020dividemix}
\abx@aux@cite{li2020dividemix}
\abx@aux@segm{0}{0}{li2020dividemix}
\abx@aux@cite{li2020dividemix}
\abx@aux@segm{0}{0}{li2020dividemix}
\abx@aux@cite{li2020dividemix}
\abx@aux@segm{0}{0}{li2020dividemix}
\abx@aux@cite{berthelot2019mixmatch}
\abx@aux@segm{0}{0}{berthelot2019mixmatch}
\abx@aux@cite{kurakin2020remixmatch}
\abx@aux@segm{0}{0}{kurakin2020remixmatch}
\abx@aux@cite{kurakin2020remixmatch}
\abx@aux@segm{0}{0}{kurakin2020remixmatch}
\abx@aux@cite{bridle1992unsupervised}
\abx@aux@segm{0}{0}{bridle1992unsupervised}
\abx@aux@cite{bridle1992unsupervised}
\abx@aux@segm{0}{0}{bridle1992unsupervised}
\newlabel{eq:nrloss}{{1}{3}{Noisy labeling and noise-robust loss}{equation.2.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{SSL for noisy labeling and a potential solution for asymmetric noise.}{3}{paragraph*.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Model bias in SSL.}{3}{paragraph*.3}\protected@file@percent }
\abx@aux@cite{kurakin2020remixmatch}
\abx@aux@segm{0}{0}{kurakin2020remixmatch}
\abx@aux@cite{kurakin2020remixmatch}
\abx@aux@segm{0}{0}{kurakin2020remixmatch}
\abx@aux@cite{sohn2020fixmatch}
\abx@aux@segm{0}{0}{sohn2020fixmatch}
\newlabel{eq:mi}{{2}{4}{Model bias in SSL}{equation.2.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{4}{section.3}\protected@file@percent }
\newlabel{sec:method}{{3}{4}{Methods}{section.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}FixMatch}{4}{subsection.3.1}\protected@file@percent }
\newlabel{eq:bsl}{{4}{4}{FixMatch}{equation.3.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Investigation of noisy (pseudo) labels and confirmation errors of FixMatch}{4}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Nosiy pseudo labels and confirmation errors in FixMatch.}{4}{paragraph*.4}\protected@file@percent }
\abx@aux@cite{li2020dividemix}
\abx@aux@segm{0}{0}{li2020dividemix}
\abx@aux@cite{sohn2020fixmatch}
\abx@aux@segm{0}{0}{sohn2020fixmatch}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Investigation with class-balanced batches.}{5}{paragraph*.5}\protected@file@percent }
\newlabel{eq:eqr}{{5}{5}{Investigation with class-balanced batches}{equation.3.5}{}}
\abx@aux@cite{sohn2020fixmatch}
\abx@aux@segm{0}{0}{sohn2020fixmatch}
\abx@aux@cite{sohn2020fixmatch}
\abx@aux@segm{0}{0}{sohn2020fixmatch}
\abx@aux@cite{cubuk2020randaugment}
\abx@aux@segm{0}{0}{cubuk2020randaugment}
\abx@aux@cite{kurakin2020remixmatch}
\abx@aux@segm{0}{0}{kurakin2020remixmatch}
\abx@aux@cite{sohn2020fixmatch}
\abx@aux@segm{0}{0}{sohn2020fixmatch}
\abx@aux@cite{krizhevsky2009learning}
\abx@aux@segm{0}{0}{krizhevsky2009learning}
\abx@aux@cite{sohn2020fixmatch}
\abx@aux@segm{0}{0}{sohn2020fixmatch}
\abx@aux@cite{sohn2020fixmatch}
\abx@aux@segm{0}{0}{sohn2020fixmatch}
\abx@aux@cite{sohn2020fixmatch}
\abx@aux@segm{0}{0}{sohn2020fixmatch}
\abx@aux@cite{sohn2020fixmatch}
\abx@aux@segm{0}{0}{sohn2020fixmatch}
\abx@aux@cite{sohn2020fixmatch}
\abx@aux@segm{0}{0}{sohn2020fixmatch}
\newlabel{eq:cer}{{6}{6}{Investigation with class-balanced batches}{equation.3.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4}Data Preprocessing and Augmentation}{6}{section.4}\protected@file@percent }
\newlabel{sec:data}{{4}{6}{Data Preprocessing and Augmentation}{section.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5}Experiment}{6}{section.5}\protected@file@percent }
\abx@aux@cite{zagoruyko2016wide}
\abx@aux@segm{0}{0}{zagoruyko2016wide}
\abx@aux@cite{sohn2020fixmatch}
\abx@aux@segm{0}{0}{sohn2020fixmatch}
\abx@aux@cite{cubuk2020randaugment}
\abx@aux@segm{0}{0}{cubuk2020randaugment}
\abx@aux@cite{cubuk2020randaugment}
\abx@aux@segm{0}{0}{cubuk2020randaugment}
\abx@aux@cite{sohn2020fixmatch}
\abx@aux@segm{0}{0}{sohn2020fixmatch}
\abx@aux@cite{sohn2020fixmatch}
\abx@aux@segm{0}{0}{sohn2020fixmatch}
\abx@aux@cite{sohn2020fixmatch}
\abx@aux@segm{0}{0}{sohn2020fixmatch}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Reproducibility}{7}{subsection.5.1}\protected@file@percent }
\newlabel{sec:rep}{{5.1}{7}{Reproducibility}{subsection.5.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{CIFAR-10.}{7}{paragraph*.6}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Error rates for CIFAR-10 on test data. FixMatch (RA) uses RandAugment \citep {cubuk2020randaugment}. BC means that the experiment uses balanced-class batches as introduced in Sec. \ref  {sec:method}. We use the experiment with BC and RA as a comparison baseline results for the investigation in Sec. \ref  {sec:exp_noise}. \relax }}{7}{table.caption.7}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:err}{{1}{7}{Error rates for CIFAR-10 on test data. FixMatch (RA) uses RandAugment \citep {cubuk2020randaugment}. BC means that the experiment uses balanced-class batches as introduced in Sec. \ref {sec:method}. We use the experiment with BC and RA as a comparison baseline results for the investigation in Sec. \ref {sec:exp_noise}. \relax }{table.caption.7}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Barely supervised learning.}{7}{paragraph*.8}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Ablation studies}{7}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Study for Confidence threshold.}{7}{paragraph*.9}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Ratio of unlabeled data.}{7}{paragraph*.11}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Plots of various ablation studies on FixMatch compared with those reported in the paper. (a) Varying the confidence threshold for pseudo-labels in the original paper. (b) Varying the ratio of unlabled data ($\mu $) in the original paper. (c)Varying the confidence threshold for pseudo-labels based on our implementation. (d) Varying the ratio of unlabled data ($\mu $) based on our implementation. \relax }}{8}{figure.caption.10}\protected@file@percent }
\newlabel{fig:abastudy}{{1}{8}{Plots of various ablation studies on FixMatch compared with those reported in the paper. (a) Varying the confidence threshold for pseudo-labels in the original paper. (b) Varying the ratio of unlabled data ($\mu $) in the original paper. (c)Varying the confidence threshold for pseudo-labels based on our implementation. (d) Varying the ratio of unlabled data ($\mu $) based on our implementation. \relax }{figure.caption.10}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Investigation on confirmation errors and asymmetric noisy (pseudo) labels}{8}{subsection.5.3}\protected@file@percent }
\newlabel{sec:exp_noise}{{5.3}{8}{Investigation on confirmation errors and asymmetric noisy (pseudo) labels}{subsection.5.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Existence of asymmetric noise and confirmation errors in pseudo labels.}{8}{paragraph*.12}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Equal-frequency and confidence entropy regularization on the labeled data.}{8}{paragraph*.14}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Confusion matrices of the confident prediction on unlabeled data with different batch structures. Confusion matrices are plotted every 100 training steps in the 1st epoch (1024 steps). The \textbf  {top} matrices are from the experiments without BC, and the \textbf  {bottom} matrices are the ones with BC. The red areas represent the asymmetric noise in the pseudo labels. The bottom matrices have a stable and smooth transition while the top matrices have a fluctuating transition in the red areas. The yellow color represents larger value and the darker green color represents smaller values. \relax }}{9}{figure.caption.13}\protected@file@percent }
\newlabel{fig:cfmx}{{2}{9}{Confusion matrices of the confident prediction on unlabeled data with different batch structures. Confusion matrices are plotted every 100 training steps in the 1st epoch (1024 steps). The \textbf {top} matrices are from the experiments without BC, and the \textbf {bottom} matrices are the ones with BC. The red areas represent the asymmetric noise in the pseudo labels. The bottom matrices have a stable and smooth transition while the top matrices have a fluctuating transition in the red areas. The yellow color represents larger value and the darker green color represents smaller values. \relax }{figure.caption.13}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Error rates on testing data using the loss function \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:eqr}\unskip \@@italiccorr )}} and \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:cer}\unskip \@@italiccorr )}}. The experiments use 150 labeled data and CTA for training. The first column is the results without BC batch and the second column is the baseline result without using EF or CE regularization.\relax }}{9}{table.caption.15}\protected@file@percent }
\newlabel{tab:hp_e}{{2}{9}{Error rates on testing data using the loss function \eqref {eq:eqr} and \eqref {eq:cer}. The experiments use 150 labeled data and CTA for training. The first column is the results without BC batch and the second column is the baseline result without using EF or CE regularization.\relax }{table.caption.15}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {paragraph}{Equal-frequency and confidence entropy regularization on the labeled data containing asymmetric noise.}{9}{paragraph*.17}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Confusion matrices of the confident prediction on unlabeled data with BC batches using loss functions \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:bsl}\unskip \@@italiccorr )}} without entropy regularization at \textbf  {top}, \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:eqr}\unskip \@@italiccorr )}} with equal-frequencey entropy regularization in the \textbf  {middle}, and \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:cer}\unskip \@@italiccorr )}} with confidence entropy regularization at \textbf  {bottom}. Confusion matrices are plotted every 100 training steps in the 1st epoch (1024 steps). The red areas represent the asymmetric/symmetric noise in the pseudo labels. The yellow color represents larger value and the darker green color represents smaller values. \relax }}{10}{figure.caption.16}\protected@file@percent }
\newlabel{fig:cfmx_eta}{{3}{10}{Confusion matrices of the confident prediction on unlabeled data with BC batches using loss functions \eqref {eq:bsl} without entropy regularization at \textbf {top}, \eqref {eq:eqr} with equal-frequencey entropy regularization in the \textbf {middle}, and \eqref {eq:cer} with confidence entropy regularization at \textbf {bottom}. Confusion matrices are plotted every 100 training steps in the 1st epoch (1024 steps). The red areas represent the asymmetric/symmetric noise in the pseudo labels. The yellow color represents larger value and the darker green color represents smaller values. \relax }{figure.caption.16}{}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Error rates of FixMatch methods in the presence of asymmetric noise in labeled training data augmented by RA: The baseline method ($\lambda =0$); The method ($\lambda =0$) with BC batches; the method with confidence-entropy regularization ($\lambda _{ce}=0.1$) and BC batches; the method with equal-frequency regularization ($\lambda _{ef}=0.1$) and BC batches. \relax }}{10}{table.caption.18}\protected@file@percent }
\newlabel{tab:ans}{{3}{10}{Error rates of FixMatch methods in the presence of asymmetric noise in labeled training data augmented by RA: The baseline method ($\lambda =0$); The method ($\lambda =0$) with BC batches; the method with confidence-entropy regularization ($\lambda _{ce}=0.1$) and BC batches; the method with equal-frequency regularization ($\lambda _{ef}=0.1$) and BC batches. \relax }{table.caption.18}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6}Challenges}{10}{section.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{11}{section.7}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {8}Ethical consideration}{11}{section.8}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{ADC1E0E5D7E40550CF70390EC1C39222}
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{zoubin2020}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{kuznetsova2018open}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{tajbakhsh2016convolutional}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{pmlr-v124-kugelgen20a}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{sohn2020fixmatch}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{berthelot2019mixmatch}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{kurakin2020remixmatch}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{li2020dividemix}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{ben2008does}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{chapelle2010semi}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{scholkopf2012causal}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{tarvainenweight}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{zhang2018generalized}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{ghosh2015making}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{patrini2017making}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{arazo2019unsupervised}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{bridle1992unsupervised}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{cubuk2020randaugment}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{krizhevsky2009learning}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{zagoruyko2016wide}{none/global//global/global}
\gdef \@abspage@last{12}
